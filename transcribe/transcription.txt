 Hola, soy Eric Johnson, es el 18 de febrero de 2021 y este es el review de la quídera de ingeniería en GitLab. Así que tengo número 4 en la agenda, que es un propósito para romper este mes en cuatro reviews de la quídera de departamento. Entonces, ahora este es el review de la quídera de ingeniería, desarrollo, calidad, seguridad y Ux, infraestructura y apoyo a sus propias reviews. Tengo las razones de que la visibilidad de la creación de la visibilidad, de poder ir más allá, de aumentar la objetividad con la que mis reportes pueden manejar sus grupos, de darme más tiempo para enfocar en nuevos mercados y de darme el tiempo para moverme a más de una pregunta de la moda de la quídera, de generar contenido y de responder preguntas en estos mesos. Pero para evitar añadir tres mesos a los calendarios de los stakeholders, supongo que hacemos una rotación de dos meses, así que el 1 de mes, el desarrollo y la calidad de la quídera, el 2 de mes, la seguridad y la Ux. ¿Cómo las personas sienten ese propósito? Creo que en las conversaciones del grupo están trabajando muy bien, así que estoy apoyado. Y esto es la más pequeña cosa, porque creo que tenemos que tener un mes, como el departamento más grande, es muy importante, pero si propusas esto, no, podría verlo, así que vamos a poner el propósito. Bien, vamos a probarlo y podemos ser flexibles, el desarrollo es mayor, quizá se ve más frecuentemente o algo así, pero vamos a ver cómo va. Bien, y luego tengo número 5, que es que tenemos R&D overall MR-rate, y también tenemos R&D mayor MR-rate, tanto como top level KPIs para el engenaje. Entonces, el diferencia entre ellos, en el sencillo, es que el R&D mayor MR-rate incluye las contribuciones comunitarias y las MR-rate comunitarias. Los problemas que veo con esto son que el rato mayor MR-rate, el que incluye internally y extranjero MR-rate, duplicó el rato mayor overall, que es el rato mayor de la comunidad. Lo siento, lo siento, el rato mayor MR-rate es el rato mayor, y el rato mayor debe ser más narrow y más grande. Es como si dijimos que es la comunidad más grande. Right, right, right. Ok, so there's... I'll have to check the taxonomy. Lily, can you confirm SID's reasoning as my understanding as well? Yeah, I believe water MR-rate just captures community contributions. Only and no internal. So, what can we measure that is that one of the most likely failure modes is that we lose the community. Yeah, so... Eric, where it gets goofy is that when you look at a specific team within the company, there could be contributions outside of that that aren't community contributions. They would be viewed as community contributions by that group, but effectively they're not from outside the company. So that's why we use wider to kind of reflect that. The rato is very specific to the team. Are you saying that if someone in plan contributes to verify, it's viewed as wider? Not quite that, plan and verify are just fine. It's when you look at like the development versus infrastructure, infrastructure will often times contribute to developments work, but it won't be counted as MRs. Ok, that's a potential bit of funkiness that we should talk about separately. I don't have that in my sort of critique of this, but that doesn't necessarily make intuitive sense to me. So then I think part of my critique of this can be thrown out, because it's not as duplicative as I thought, but I still think there's a problem with R&D wider MR rate, which is this thing doesn't really move, in part because it's a rate. So it feels like the way to drive this up is to specifically drive community authors to contribute more than one MR per month. That's how this moves up, because it's a productivity rate like we use internally. And that doesn't necessarily feel like the right thing, because there's scenarios in which this goes up, and we've actually got less contributions overall and less contributors overall. Wait, wait, wait a second. So you're saying that R&D wider MR rate is number MRs per external contributor? Oh my goodness, that should not be the thing. It should be contributions per GitLab team member. So the thing above the division is the external ones. The thing below is the number of team members at GitLab. Is that the case, Lily? I'm checking right now. I think so in our new year. So we're just clarifying here. So our numerator is community contributions, and then our denominator is GitLab team members. So it's not per external member. So what we're doing there, Eric, is we're not trying to say how many MRs does someone send if they send something. We're saying how many MRs from external do we get for the size of our organization. So maybe explain the context behind this. The context is as we grow as a company, we should make sure we keep the community up. The logical thing is for the community to flatline and the size of New York to grow. And before you know it, you've kind of outgrown the wider community. Yeah, what I'm seeing is we created this pre-saviscated taxonomy with prefixes and postfixes to talk about these things. But in reality, we've only got two of them. And we keep forgetting, and we have a hard time discussing this thing. So I'd rather just name them simply two names for what they are, rather than using the taxonomy. But also, in F, I have this proposal of, what if we just tracked as a KPI the percentage of total MRs that come from the community over time. And we would see that drop. I love that. I love that. Let's do that instead. Okay. But the thing, the thing why we have this complex thing is because you can game that, you wanna game that, you just produce fewer MRs with the engineers at GitLab. So if you drive that really hard and say, this is your number one goal, it's very easy to achieve, you just tell all your engineers to produce half. Yeah, so we have, we have different metrics to prevent that from happening and we have a lot of different things to do with it. So I'd rather just give you a small summary that like support SLAs and a set kind of buttress one another. I think we're, we're robust to that, but simplifying this would make these conversations go much better. If, if you, as a, our CTO don't even understand them, we went overboard. So I'm supportive. I understand them and I forgot. And I was agreeing to stuff this morning. I'm like, there's a problem with this. And then you just remind me of the context. So yeah, if I can't, I'll just ask about, let's do that. Okay. Cool. So, Lily, if you can work with max to make that transition, that would be great. And I'll bold the one that we're talking about. And that's room and room all three. Thanks. I'm on the call. Sorry. It was a bit late timeline. We do have PIs on the raw number of community MRs. And we can make, make the shift and wider confirming from the definition. I think why the only counts for community. And then that's, that's what the definition is. Cool. All right. So number six, then Christopher. Sara is looking up to see if I had the percentage graph cause I think we played around with this at one point and had a draft of that, probably about five months back. If I can remember Lily. just enough way at month of February, if you were looking at any particular metric recipe or particular metrics, particularly in development at a MR rate. We haven't had updates in four days. There's apparently a lag issue that's been problematic for the data team to basically get updated metrics and they're working on that. I'm sorry, you got the next one. So yeah, there's some color there on the on medication, the lag later on. On to seven, we continue as an FYI in addition to the KPIs. I'm sorry, I wanted to just touch on the postgres replication issue there real quick. I'm trying to get my arms wrapped around it. Do we have the right attention to this? This is kind of Eric, I don't know if you were commenting on hinting towards this in the last meeting around some of the infrastructure improvements on the product side. I'm just not quite sure whose responsibility it is to focus on getting a handle on some of the constraints we have in replication. Yeah, what I was mentioning in the product review about an hour ago is I think it's sort of like unrelated. And so I think the DRI needs to be your kind of data engineering team. But of course, there's a dependency on infrastructure because that's where the data is being piped from. They do own that data source. Yeah, I'll say for the replication lag on that slave host where I'm sorry, not the on the secondary host where the data is being pulled from like infrastructure would be the DRI for that. And so any escalations, but I'll own those. And I know we have an action plan for that as far as creating another dedicated host just for the data team to pull from. Okay. I did ask, I saw that issue and I did talk to Craig Gomes a little bit as well on the database side just to see if there's some database improvements. And I'm still trying to figure out, you know, if it's truly just dedicated computational sort of resources of server, or if there's actually some some database tuning that needs to occur. Do you have a sense of that? There's so I'd say it's it's three different things. It's having a dedicated host that doesn't have conflicting query traffic coming from other other workloads. There are some tuning performance or tuning improvements to be made. And then there's also improvements in this is where it does maybe relate a little bit to what the topic was in the last review. Basically, the overall demand on the database layer from dot com activities and like improving those. So it's it's definitely not just one of those things. But one of the most specific actions we're going to take though is separating out and having a dedicated host so that we're just dealing with the profile of the data engineering traffic on there. And not having conflicting query. Conflicting queries, affect the ability to update the replication. Steve, I definitely want to partner with you on this one, because I think the demand on those databases is only going to increase. It's not going down. And I think we need to get. I'm still unclear on where to focus and to get the biggest bang for the buck. I think of the computational resource dedication. That's going to be a good thing, but I'll probably squeeze the balloon. And then the next area will will honor itself. Okay, I'll put into the infra key review for next week. Okay, an update on this issue. Thank you, Steve. So then back to mech on seven. Or. Yes. Thank you. And Rob was in the assassin's event this morning as well. Brian, just we have the attention there. Number seven, just provide provide an update on previous conversations. We continue to improve defect tracking and against us. There is a first iteration PR that we are experimenting to show percentage of defects meeting. We are also working on the measurement for average open bugs age. This would give us a whole picture of what's what's left. The age goes up or down to be or clean the backlog. The average age should go down as well. The average age. No se crea, on this too. Yeah, just I was looking through the charts and I noted that there was a spike. And meantime, the close. Yeah. And. And we're going to have a look at the updates. And then we're going to have a look at the updates. And then we're going to have a look at the updates. So, I'm going to go to the charts and I noted that there was a spike in meantime to close. Yeah. And just wanted to see if you had any insight into that press. This is the S2. The S1 looked fine. So. Yeah. This is where the point be on age. And supplement the charts in the back and helps. So I haven't seen a dip in age. Nor the count overall. I think I think it's the latter. We need to dig in a bit deeper in that. And also the data lag. I think we have a whole picture. And everything is synced in a, as well. Christy, you have some insights. Yeah. I'm just wondering if part of this could be the fact that we changed the severity across the board for MRs. To S2. And so we may have some older bugs in there that hadn't been addressed because they were at a lower severity. Now we've moved them to S2 and maybe that caused a little spike. That could be the case. If we did it in a limited fashion, it won't be a huge volume. We also iterated after that to pin on priority. Since product owns prioritization. So I wouldn't account it entirely to that. I mean, this, this isn't the infer key review, but. I know that they've gotten backed up on. On those issues. So if some, some good portion of those are. Infra created or related, then that might be lifting it as well. I can take the, the, the deeper dig in and then provide an update next time. I think we need extra debug. Slicing of the data here. Sigu, would like to go to point eight. Yeah, we are now measuring as one as two SLO. Achievement with closed bugs. But if you then. Look at the, the number of bugs, it's exponential growth. And then it will be trivial to us. We are going to go to point eight. So. So. So. So. So. So. So. So. So. So. So. So. So. So we'll have. So. So we will have 2. It would be trivial to us. To achieve 100% SLO achievement. If you just look at closed bugs, even though there would be a major problem in the company, 99% of all bugs are overdue. la población y los percentage de los es dentro del tiempo de la SLO. Creo que estamos haciendo de la razón. Gracias por la feedback. Por lo tanto, queremos tener la edad anteriora para comprobar lo que está en el abrir. Podemos hacer esta iteración para también comprobar la concentración de la edad de todos los open bugs. Esto es algo que hemos hablado con Christopher en la próxima iteración. Y estamos muy felices para ajustar. Ahorita, la edad anteriora se va a dar más cerca. No es lo que me propongo. Lo que me propongo es que de los open bugs el percentage de los es dentro del SLO. Displica el percentage. Hacemos lo que es el abrir, no los es dentro del abrir. El excedente SLO para los open bugs. O los open bugs que están dentro del SLO. Tiene un gráfico que debería ir a la derecha. Todo lo que es más. Sabe bien. Podemos llevarlo a la próxima data metrics. Para que se despliega con esto. Gracias. Es un poco truco, Mack. Tendrán que figurelo. Porque queremos tener chartes que podemos reconstruir históricamente si necesitamos. Cuando los tíquets se despliegan, se despliegan por la historia. Para saber si es la hora de que se despliega. Si es la hora de que se despliega. Es un buen punto. Es mucho más difícil de computación. Así que, me respeto si podemos hacerlo por esa razón. Gracias, Craig. Me gustaría preguntar a la team. Me gustó todo el métrico de meeting. Todo lo que se veía en línea con prioridades. Esa es la cosa que la team quiere llamar. Especialmente que deberíamos verla. Sí, lo voy a llamar a Sus. Así que, la buena noticia es que en la cu4 tuvimos nuestro más pequeño despliegue por varias cuerdas. Así que solo se despliega por un punto 10. La cuarta de la cuarta de la cuarta fue un punto 10. Y la cuarta antes de eso fue un punto completo. Así que, vemos esto como un improvement. Aunque es una stilla de despliegue, pero es una stilla de despliegue. Obviamente, queremos que se despliegue en una dirección superior. También no tenemos suficiente data para saber si es una actual tendencia real. Así que, estoy optimista. Creo que es una buena cosa. Hemos tenido un foco mucho más quino.いつisado. Algunos Meyer rem tilt con la duración de exhibitar el�gla. Piguet y la leyenda sin interrayer, should we need to get more security work prioritized or hearing that from the team, but neither that problem nor that activity is sort of currently reflected in our security metrics. So we have some work to do long term to make sure that we see things like that in the metrics and the measurements that we're making. So back to you, Sid. Ten. Yeah, narrow MR rate seems significantly below target. And maybe I hope that it would bounce back from December. I think it bounced back, but not back on target. Any context there? What's what's going on? Yeah, so. With family and friends days, we actually had some heavier vacation days. En January, then we historically have one thing to note is that we are actually at a higher MR rate. If you look, if you go back the last 18 months, or actually to have higher narrow MR rate, then we were back in each month this year. So if you compare October to October, November to November, and January, I'm sorry, October, November, December, January comparatively to last year, which you'll find is between a half point and a 1.5 MR rate above where we were in the month of previous year. That's great context. Thank you, Christopher. Good work. Yeah, so the expectation is, is that February is a short month. We are at I think 16 workdays with friends and family day and other things. Obviously, seven carriages in Texas doesn't help things either for the folks who are working in Texas. But hopefully the rest of the team is being effective. I was hoping to see a better result right now, but with four or five days, particularly around release week. That's usually when we see do do see a little bit higher activity. So that's not accounted for yet. But you know, marches, marches, when I'm expecting kind of see a real rebound much like we did last year. Awesome. Thanks. The other context I'll give is we now do time series targets. So when we change the target, you'll see that reflected in the line. So if we were to look back historically here, the goal here was actually lower and Christopher was ambitious. So we kept raising and we kept meeting that. So it should stair step here and we could go back and reconstruct that if we really wanted to. And then ignoring the sort of the seasonal dip here, we raised it to I think 11. And then we realized we're kind of hitting that point of doing reaching returns and the right thing to do business wise. And this is in our F22 direction is hold the line at productivity, but start to raise other things related to quality, security, availability and what not. So that's kind of why you're seeing this bump as we raised it. And we realized, OK, that's not there. We shouldn't raise it anymore and we brought it back down to 10. So 10 will be the target going forward. I'm going to try to get better. A lot of other things while preventing this from dipping. Cool. And I just want to call out that it's not necessary. Like higher MRA should also help to address security and quality and other things because you're more productive so you can fix more things. So it's not necessarily opposite. But I agree with. Let's hold the line 10 is a great number and focus on other indicators to improve. That makes a ton of sense. Cool. Well said. All right. That's it for the agenda. Anyone want to vocalize anything else? Great. Well, thanks everybody. And I'm going to go check on my four year old and see if she got whatever she needed. So cheers and talk soon. Thanks, sir.